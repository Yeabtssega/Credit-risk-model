Credit Risk Model â€“ Bati Bank
Author: Yeabtsega Tilahun
Organization: Bati Bank
Project: Credit Scoring for Buy-Now-Pay-Later Loan Approvals
Submission: Final | July 1, 2025

ğŸ“˜ Project Overview
Bati Bank is partnering with a successful eCommerce company to launch a Buy-Now-Pay-Later (BNPL) service. As the Analytics Engineer, you're tasked with designing and deploying a Credit Scoring Model that assesses the credit risk of customers using behavioral transaction data.

This project delivers a complete ML workflowâ€”from data preprocessing and feature engineering to risk modeling, CI/CD deployment, and an interactive prediction API.

ğŸ¯ Business Objective
Credit scoring quantifies the likelihood that a borrower will default on a loan. Our key innovation is transforming customer transaction behavior (RFM metrics) into a proxy for credit risk, enabling risk-based loan decisioning.

âœ… Goal: Assign risk probability scores and recommend credit terms for new customers using transaction behavior.

ğŸ’¼ Credit Scoring Business Understanding
1. Why does Basel II demand an interpretable model?
Basel II emphasizes transparency, accountability, and regulatory compliance. Financial institutions must explain how and why a credit decision was made. Therefore, interpretable models (like logistic regression with Weight of Evidence) are preferred for traceability.

2. Why create a proxy target variable?
The dataset lacks an explicit â€œdefaultâ€ label. We create a proxy using RFM clustering, defining "high-risk" customers based on low frequency and monetary values. This approach enables modeling, but comes with business risk: poor proxy definitions may misclassify customers, leading to biased decisions.

3. Simple vs Complex Models: Whatâ€™s the trade-off?
Simple (e.g., Logistic Regression + WoE): Interpretable, compliant, easier to audit

Complex (e.g., Gradient Boosting): Higher accuracy but less transparent
In regulated sectors, the cost of opacity may outweigh marginal accuracy gains.

ğŸ—‚ï¸ Project Structure
bash
Copy
Edit
credit-risk-model/
â”œâ”€â”€ .github/workflows/ci.yml        # CI/CD: lint + unit tests
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Raw data (ignored in Git)
â”‚   â””â”€â”€ processed/                  # Processed, ready-to-train
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 1.0-eda.ipynb               # Exploratory Data Analysis
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing.py          # Feature Engineering
â”‚   â”œâ”€â”€ train.py                    # Model training & MLflow
â”‚   â”œâ”€â”€ predict.py                  # Model inference
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ main.py                 # FastAPI backend
â”‚       â””â”€â”€ pydantic_models.py      # Input/Output schemas
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_data_processing.py     # Unit tests
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
ğŸ“Š Key Tasks and Results
âœ… Task 1 â€“ Basel II & Business Framing
Defined credit risk modeling scope

Identified need for transparency and proxy labels

âœ… Task 2 â€“ Exploratory Data Analysis (EDA)
Uncovered outliers and missing values

Identified patterns in transaction amount, fraud, and product use

Summarized top insights in Jupyter Notebook

âœ… Task 3 â€“ Feature Engineering
Created:

Aggregate features (Total amount, Count, Avg)

Temporal features (Day, Hour, Month)

Encoded categorical variables

Normalized numerical data

Used xverse and woe for feature selection and scoring

âœ… Task 4 â€“ Proxy Variable Creation
RFM (Recency, Frequency, Monetary) engineered

Used KMeans clustering for customer segmentation

Defined is_high_risk = 1 for the lowest value cluster

âœ… Task 5 â€“ Model Training and Evaluation
Trained multiple models: Logistic Regression, Gradient Boosting

Evaluated using ROC-AUC, F1, Accuracy

Tracked experiments using MLflow

Registered the best model to MLflow Model Registry

Created automated unit tests with pytest

âœ… Task 6 â€“ Model Deployment & CI/CD
Deployed prediction API using FastAPI

Dockerized app with Dockerfile and docker-compose.yml

CI pipeline runs on every push:

flake8 for linting

pytest for test coverage

/predict endpoint accepts new customer data and returns:

Risk probability

Credit score (scaled)

Loan amount and duration recommendations

ğŸ§  Learning Outcomes
Tools & Skills Used:
scikit-learn, mlflow, pytest, FastAPI, Docker

CI/CD with GitHub Actions

Model management with MLflow

Python best practices: pipelining, modular code, testing

Real-World Takeaways:
End-to-end ML systems must be automated, interpretable, and deployable

Proxy targets enable learning without perfect ground-truth

Regulatory alignment is as important as predictive power

ğŸš€ How to Run the Project
ğŸ”§ Local API Setup
bash
Copy
Edit
git clone https://github.com/Yeabtssega/Credit-risk-model.git
cd Credit-risk-model
docker-compose up --build
ğŸ” Test API
Visit: http://127.0.0.1:8000/docs
Use Swagger UI to test the /predict endpoint.

ğŸ“š References
Statistical Models for Credit Scoring

Credit Scoring Guidelines - World Bank

Basel II Accord Summary

Weight of Evidence & IV Explanation

âœ… Final Submission
ğŸ¯ GitHub Repo: github.com/Yeabtssega/Credit-risk-model
ğŸ“¦ Submission: July 1, 2025, 8PM UTC

